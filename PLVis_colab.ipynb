{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWh4ciN08kU3"
      },
      "source": [
        "#Protein Language Visualization (PLVis) Colab Notebook\n",
        "Use this Colab Notebook to generate your own PLVis for proteome comparisons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oAJFn75nD0sX"
      },
      "outputs": [],
      "source": [
        "#@title Step 1. Import Dependencies\n",
        "#@markdown Run this cell to import all the necessary dependencies.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(77)\n",
        "import more_itertools\n",
        "import os\n",
        "import io\n",
        "import re\n",
        "import h5py\n",
        "import gzip\n",
        "import requests\n",
        "import PIL\n",
        "import itertools\n",
        "import random\n",
        "import seaborn as sns\n",
        "import urllib.request\n",
        "import urllib.error\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "from collections import Counter\n",
        "from fontTools import ttLib\n",
        "\n",
        "from datetime import datetime\n",
        "current_date = datetime.now().date()\n",
        "date = current_date.strftime('%Y-%m-%d')\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, pairwise_distances\n",
        "\n",
        "from nltk import ngrams, FreqDist\n",
        "\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "!pip install umap-learn --quiet\n",
        "import umap\n",
        "\n",
        "!pip install datamapplot --quiet\n",
        "import datamapplot\n",
        "\n",
        "!pip install ipywidgets --quiet\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "!pip install graphein --quiet\n",
        "!pip install graphein[extras] --quiet\n",
        "from graphein.protein.utils import download_alphafold_structure\n",
        "\n",
        "!pip install py3Dmol --quiet\n",
        "import py3Dmol\n",
        "\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "\n",
        "print('Imported dependencies')\n",
        "\n",
        "#DMP FUNCTIONS\n",
        "def get_data(df):\n",
        "    data_map = df[['UMAP 1', 'UMAP 2']].to_numpy().astype('float32')\n",
        "\n",
        "    data_list = []\n",
        "    for index, row in df.iterrows():\n",
        "        entry = row['Entry'] if 'Entry' in row else 'N/A'\n",
        "        protein = row['Protein names'] if 'Protein names' in row else 'N/A'\n",
        "        organism = row['Organism'] if 'Organism' in row else 'N/A'\n",
        "        gene = row['Gene Names'] if 'Gene Names' in row else 'N/A'\n",
        "        pathway = row['Pathway'] if 'Pathway' in row else 'N/A'\n",
        "        anot = row['Annotation'] if 'Annotation' in row else 'N/A'\n",
        "        label = row['Cluster Label']\n",
        "        text = f\"Entry: {entry}\\nProtein Names: {protein}\\nOrganism: {organism}\\nGene Names: {gene}\\nPathway: {pathway}\\nAnnotation: {anot}\\nCluster: {label}\"\n",
        "        data_list.append(text)\n",
        "    hover_data = np.array(data_list).astype(str)\n",
        "\n",
        "    clusters = sorted(df['Cluster Label'].unique())\n",
        "    name_map = {}\n",
        "    for cluster in clusters:\n",
        "        current_cluster = df[df['Cluster Label'] == cluster]\n",
        "        prot_names = current_cluster['Protein names'].tolist()\n",
        "        prot_names = [re.sub(r'\\([^)]*\\)|\\[[^\\]]*\\]', '', str_test) for str_test in prot_names]\n",
        "        words = [name.split() for name in prot_names]\n",
        "        word_list = [item for sublist in words for item in sublist]\n",
        "        dict_counts = FreqDist(ngrams(word_list, 2))\n",
        "\n",
        "        if len(dict_counts)==0:\n",
        "            max_counts = ('No', '', 'label',)\n",
        "        else:\n",
        "            max_counts = max(dict_counts, key=dict_counts.get)\n",
        "\n",
        "        cluster_name = ' '.join(max_counts)\n",
        "        name_map[cluster] = f'{cluster}. {cluster_name}'\n",
        "\n",
        "    df['Cluster Name'] = df['Cluster Label'].map(name_map)\n",
        "    labels = (df['Cluster Name']).to_numpy().astype(str)\n",
        "\n",
        "    return(data_map, hover_data, labels)\n",
        "\n",
        "def get_customs(color_mapping):\n",
        "    custom_css=\"\"\"\n",
        "    .row {\n",
        "        display : flex;\n",
        "        align-items : center;\n",
        "    }\n",
        "    .box {\n",
        "        height:10px;\n",
        "        width:10px;\n",
        "        border-radius:2px;\n",
        "        margin-right:5px;\n",
        "    }\n",
        "    #legend {\n",
        "        position: absolute;\n",
        "        bottom: 0;\n",
        "        right: 0;\n",
        "        margin: 16px;\n",
        "        padding: 12px;\n",
        "        border-radius: 16px;\n",
        "        z-index: 2;\n",
        "        background: #ffffffcc;\n",
        "        font-family: Cinzel;\n",
        "        font-size: 8pt;\n",
        "        box-shadow: 2px 3px 10px #aaaaaa44;\n",
        "    }\n",
        "    #title-container {\n",
        "        max-width: 75%;\n",
        "    }\n",
        "    \"\"\"\n",
        "    custom_html = \"\"\"\n",
        "    <div id=\"legend\">\n",
        "    \"\"\"\n",
        "    for field, color in color_mapping.items():\n",
        "        custom_html += f'    <div class=\"row\"><div id=\"{field}\" class=\"box\" style=\"background-color:{color};padding:0px 0 1px 0;text-align:center\"></div>{field}</div>\\n'\n",
        "    custom_html += \"\"\"\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    custom_js = \"\"\"\n",
        "        const legend = document.getElementById('legend');\n",
        "        legend.addEventListener('click', function (event) {\n",
        "                const primary_field = event.srcElement.id;\n",
        "                selectPoints(primary_field, (i) => (hoverData.data.primary_field[i] == primary_field));\n",
        "                for (const row of legend.children) {\n",
        "                    for (const item of row.children) {\n",
        "                        if (item.id == primary_field) {\n",
        "                            item.innerHTML = \"âœ“\";\n",
        "                        } else {\n",
        "                            item.innerHTML = \"\";\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "                search.value = \"\";\n",
        "            });\n",
        "\n",
        "            search.addEventListener(\"input\", (event) => {\n",
        "                for (const row of legend.children) {\n",
        "                    for (const item of row.children) {\n",
        "                            item.innerHTML = \"\";\n",
        "                        }\n",
        "                    }\n",
        "            });\n",
        "    \"\"\"\n",
        "    return(custom_css, custom_html, custom_js)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JbkP7QyPYyx"
      },
      "source": [
        "**To use the PLVis Colab Notebook, you will need the following files for each protein set:**\n",
        "\n",
        "1) A CSV, TSV or XLSX dataframe from UniProt with the following columns:\n",
        "* \"Entry\", \"Sequence\" and \"Annotation\"\n",
        "\n",
        "2) A GZ or H5 file containing the corresponding embeddings for the dataframe.\n",
        "\n",
        "---\n",
        "**IMPORTANT**\n",
        "\n",
        "Be sure to give the same name to your dataframe and embedding files before uploading.\n",
        "\n",
        "---\n",
        "\n",
        "**NOTE**\n",
        "\n",
        "If you have already generated a dataframe using this Colab, skip steps 2 through 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_A2INyLC8XBS"
      },
      "outputs": [],
      "source": [
        "#@title Step 2. Upload Dataframe and Embedding Files\n",
        "\n",
        "#@markdown Run this cell and upload ALL your protein dataframe files\n",
        "#@markdown (TSV, CSV or XLSX) and embedding files (GZ or H5).\n",
        "\n",
        "# Prompt user to upload multiple files\n",
        "print(\"Please upload your protein dataframe files (TSV, CSV or XLSX) and embeddings (GZ or H5):\")\n",
        "uploaded_files = files.upload()  # Allow multiple file uploads\n",
        "\n",
        "# Initialize the file dictionary\n",
        "file_dict = {}\n",
        "\n",
        "# Process uploaded files\n",
        "for file_name in uploaded_files.keys():\n",
        "    # Save uploaded files locally\n",
        "    with open(file_name, 'wb') as f:\n",
        "        f.write(uploaded_files[file_name])\n",
        "\n",
        "# Group files by their base names\n",
        "file_groups = {}\n",
        "for file_name in uploaded_files.keys():\n",
        "    base_name = os.path.splitext(file_name)[0]  # Extract base name without extension\n",
        "    if base_name not in file_groups:\n",
        "        file_groups[base_name] = []\n",
        "    file_groups[base_name].append(file_name)\n",
        "\n",
        "# Match data files with embeddings and process them\n",
        "for base_name, file_names in file_groups.items():\n",
        "    df_file = None\n",
        "    embedding_file = None\n",
        "    compressed = None\n",
        "\n",
        "    # Check for dataframe files\n",
        "    for file_name in file_names:\n",
        "        if file_name.endswith('.tsv'):\n",
        "            try:\n",
        "                df_file = pd.read_csv(file_name, sep='\\t')\n",
        "                print(f\"Loaded dataframe from {file_name}.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading {file_name} as TSV: {e}\")\n",
        "        elif file_name.endswith('.csv'):\n",
        "            try:\n",
        "                df_file = pd.read_csv(file_name)\n",
        "                print(f\"Loaded dataframe from {file_name}.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading {file_name} as CSV: {e}\")\n",
        "        elif file_name.endswith('.xlsx'):\n",
        "            try:\n",
        "                df_file = pd.read_excel(file_name)\n",
        "                print(f\"Loaded dataframe from {file_name}.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading {file_name} as XLSX: {e}\")\n",
        "\n",
        "        # Check for embedding files\n",
        "        elif file_name.endswith('.gz'):\n",
        "            embedding_file = file_name\n",
        "            compressed = True\n",
        "            print(f\"Found compressed embedding file: {file_name}.\")\n",
        "        elif file_name.endswith('.h5'):\n",
        "            embedding_file = file_name\n",
        "            compressed = False\n",
        "            print(f\"Found H5 embedding file: {file_name}.\")\n",
        "\n",
        "    # Ensure both dataframe and embedding file exist\n",
        "    if df_file is not None and embedding_file is not None:\n",
        "        file_dict[base_name] = {\n",
        "            'df_file': df_file,\n",
        "            'embedding_file': embedding_file,\n",
        "            'compressed': compressed\n",
        "        }\n",
        "    else:\n",
        "        print(f\"Missing pair for {base_name}. Skipping...\")\n",
        "\n",
        "# Output the results\n",
        "if file_dict:\n",
        "    print(\"\\nSuccessfully processed the following file pairs:\")\n",
        "    for key, details in file_dict.items():\n",
        "        print(f\"Base Name: {key}, DataFrame Loaded, Embedding File: {details['embedding_file']}, Compressed: {details['compressed']}\")\n",
        "else:\n",
        "    print(\"No valid file pairs were found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ohyO1Dnb9X2L"
      },
      "outputs": [],
      "source": [
        "#@title Step 3. Retrieve the PLM Embeddings\n",
        "\n",
        "#@markdown Run this cell to retrieve the protein embeddings from an H5 or GZ file.\n",
        "\n",
        "def get_embeddings (embedding_file, df_file):\n",
        "    entries_list = []\n",
        "    embeddings_list = []\n",
        "    data_map = {}\n",
        "\n",
        "    if embedding_file.endswith('.gz'):\n",
        "        output_file = embedding_file.replace('.gz', '.h5')\n",
        "        with gzip.open(embedding_file, 'rb') as f_in:\n",
        "            with open(output_file, 'wb') as f_out:\n",
        "                f_out.write(f_in.read())\n",
        "    elif embedding_file.endswith('.h5'):\n",
        "        output_file = embedding_file\n",
        "\n",
        "    with h5py.File(output_file, \"r\") as file:\n",
        "        for sequence_id, embedding in file.items():\n",
        "            entries_list.append(sequence_id)\n",
        "            embeddings = np.array(embedding)\n",
        "            embeddings_list.append(embeddings)\n",
        "            data_map[sequence_id] = embeddings\n",
        "\n",
        "    embedding_df = df_file\n",
        "    embedding_df['Embeddings'] = embedding_df['Entry'].map(data_map)\n",
        "\n",
        "    #Remove proteins without embeddings from the dataframe\n",
        "    embedding_df = embedding_df.dropna(subset=['Embeddings'])\n",
        "\n",
        "    return(embedding_df)\n",
        "\n",
        "#Updated dfs with the embeddings for each protein\n",
        "df_list = []\n",
        "for file_name in file_dict:\n",
        "    embedding_df = get_embeddings(file_dict[file_name]['embedding_file'],\n",
        "                                  file_dict[file_name]['df_file'])\n",
        "    df_list.append(embedding_df)\n",
        "\n",
        "embedding_df = pd.concat(df_list, ignore_index=True)\n",
        "print(f\"Retrieved {len(embedding_df)} embeddings\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HlueMNMD-4qA"
      },
      "outputs": [],
      "source": [
        "#@title Step 4. Reduce Dimensionality\n",
        "\n",
        "#@markdown This cell uses the **UMAP** reduction algorithm to reduce the PLM\n",
        "#@markdown embeddings to 2 dimensions.\n",
        "\n",
        "#@markdown The time it takes for this cell to run depends on the\n",
        "#@markdown size of your dataframe.\n",
        "\n",
        "try:\n",
        "    embeddings_array = np.array(embedding_df['Embeddings'].tolist())\n",
        "\n",
        "    umap_reducer = umap.UMAP(n_components = 2, random_state = 77)\n",
        "\n",
        "    embeddings_reduced = umap_reducer.fit_transform(embeddings_array)\n",
        "\n",
        "    reduced_df = embedding_df.copy()\n",
        "    reduced_df['UMAP 1'] = embeddings_reduced[:, 0]\n",
        "    reduced_df['UMAP 2'] = embeddings_reduced[:, 1]\n",
        "\n",
        "    print(\"2D reduction succesful\")\n",
        "except Exception as e:\n",
        "    print(f\"Error reducing the embeddings: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bdA00EkJ_-Mo"
      },
      "outputs": [],
      "source": [
        "#@title Step 5. Calculate the Number of Clusters\n",
        "\n",
        "#@markdown This cell calculates the number of k-means clusters for the\n",
        "#@markdown dataframe. The plot generated indicates the average silhouette\n",
        "#@markdown score for the number of clusters in the visualization, a higher score\n",
        "#@markdown means that the clusters are better defined.\n",
        "\n",
        "#@markdown The time it takes for this cell to run depends on the\n",
        "#@markdown size of your dataframe.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown The default range for this analysis is 2-100 k-means clusters.\n",
        "#@markdown If you wish to use a different upper limit, write the number in the space below.\n",
        "\n",
        "custom_range = \"\" #@param{type:\"string\"}\n",
        "if custom_range == \"\":\n",
        "    max_range = 101\n",
        "else:\n",
        "    max_range = int(custom_range) + 1\n",
        "cluster_range = range(2, max_range)\n",
        "\n",
        "def optimal_clusters(embeddings_2d, cluster_range):\n",
        "    sil_scores_kmeans = []\n",
        "\n",
        "    for n_clusters in tqdm(cluster_range):\n",
        "        kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
        "        kmeans_labels = kmeans.fit_predict(embeddings_2d)\n",
        "        sil_score_kmeans = silhouette_score(embeddings_2d, kmeans_labels)\n",
        "        sil_scores_kmeans.append(sil_score_kmeans)\n",
        "\n",
        "    optimal_clusters =  cluster_range[np.argmax(sil_scores_kmeans)]\n",
        "\n",
        "    plt.figure(figsize=(16, 10))\n",
        "    plt.plot(cluster_range, sil_scores_kmeans, markersize=5)\n",
        "\n",
        "    plt.xlabel('Number of K-means Clusters', fontsize=12, fontweight='bold')\n",
        "    plt.ylabel('Silhouette Score', fontsize=12, fontweight='bold')\n",
        "    plt.xticks(fontsize=10)\n",
        "    plt.yticks(fontsize=10)\n",
        "\n",
        "    ax = plt.gca()\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "\n",
        "    plt.show()\n",
        "    return(optimal_clusters)\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Check this box if you wish to perform clustering in high dimensions.\n",
        "high_dimension_clustering = False #@param {type:\"boolean\"}\n",
        "if high_dimension_clustering:\n",
        "  embeddings_nd= np.stack(reduced_df['Embeddings'].to_numpy())\n",
        "  kclusters = optimal_clusters(embeddings_nd, cluster_range)\n",
        "else:\n",
        "  embeddings_2d = reduced_df[['UMAP 1', 'UMAP 2']].to_numpy()\n",
        "  kclusters = optimal_clusters(embeddings_2d, cluster_range)\n",
        "\n",
        "print(f'Optimal clusters: {kclusters}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iyRA4_G6AaO8"
      },
      "outputs": [],
      "source": [
        "#@title Step 6. Save the DataFrame\n",
        "\n",
        "#@markdown This cell saves your dataframe and automatically downloads it to your computer.\n",
        "#@markdown If you do not wish to use the optimal number of clusters calculated in the previous step,\n",
        "#@markdown you can change the number of k-clusters using the space below.\n",
        "\n",
        "#@markdown Please indicate the name for the generated PLVis dataframe.\n",
        "\n",
        "file_name = \"\" #@param {type:\"string\"}\n",
        "if file_name == \"\":\n",
        "    file_name = f\"plvis\"\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Leave this space empty if you wish to use the optimal number of k-clusters.\n",
        "\n",
        "personalized_clusters = \"\" #@param {type:\"string\"}\n",
        "if personalized_clusters == \"\":\n",
        "    kclusters = kclusters\n",
        "else:\n",
        "    kclusters = int(personalized_clusters)\n",
        "\n",
        "clusters = KMeans(kclusters, n_init=10, random_state=42)\n",
        "\n",
        "complete_df = reduced_df.copy()\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Check this box if you wish to perform clustering in high dimensions.\n",
        "high_dimension_clustering = False #@param {type:\"boolean\"}\n",
        "if high_dimension_clustering:\n",
        "  complete_df['Cluster Label'] = clusters.fit_predict(embeddings_nd)\n",
        "else:\n",
        "  complete_df['Cluster Label'] = clusters.fit_predict(complete_df[['UMAP 1', 'UMAP 2']])\n",
        "\n",
        "complete_df = complete_df.drop(columns=['Embeddings'])\n",
        "complete_df.to_csv(f\"{file_name}_{date}.csv\", index=False)\n",
        "files.download(f\"{file_name}_{date}.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGyAVJMNnru9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "x8IgfcpduPTt"
      },
      "outputs": [],
      "source": [
        "#@title Load a Previously Generated Dataframe\n",
        "\n",
        "#@markdown **NOTE: Skip this cell if you created the PLVis dataframe for the first time.**\n",
        "\n",
        "#@markdown Run this cell to upload a previously generated PLVis dataframe.\n",
        "\n",
        "# Prompt the user to upload a single file\n",
        "print(\"Please upload a single file (CSV format).\")\n",
        "uploaded_file = files.upload()\n",
        "\n",
        "# Check if exactly one file is uploaded\n",
        "if len(uploaded_file) != 1:\n",
        "    print(\"Error: Please upload only one file.\")\n",
        "else:\n",
        "    # Get the file name\n",
        "    file_name = list(uploaded_file.keys())[0]\n",
        "    try:\n",
        "        # Try reading the file as a CSV\n",
        "        complete_df = pd.read_csv(file_name)\n",
        "\n",
        "        # Check if the required columns are present\n",
        "        required_columns = ['UMAP 1', 'UMAP 2', 'Cluster Label']\n",
        "        if all(col in complete_df.columns for col in required_columns):\n",
        "            print(f\"The file '{file_name}' is a valid PLVis dataframe.\")\n",
        "        else:\n",
        "            missing_columns = [col for col in required_columns if col not in complete_df.columns]\n",
        "            print(f\"The file '{file_name}' is missing the following required columns: {missing_columns}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # Handle errors (e.g., file is not a valid CSV)\n",
        "        print(f\"Error processing the file '{file_name}': {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXp6BDixvpdO"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "psITSZfm0OK5"
      },
      "outputs": [],
      "source": [
        "#@title PLVis\n",
        "\n",
        "#@markdown The following projection is a quick view of the complete dataframe.\n",
        "#@markdown Each color represents a different cluster in the data. The\n",
        "#@markdown names for each cluster are generated using n-gram analysis of the\n",
        "#@markdown protein names within the data.\n",
        "\n",
        "#@markdown Please indicate the title to be viewed with the projection.\n",
        "\n",
        "projection_df = complete_df.copy()\n",
        "data_map, hover_data, labels = get_data(projection_df)\n",
        "\n",
        "plvis_title = \"\" #@param {type:\"string\"}\n",
        "if plvis_title == \"\":\n",
        "    plvis_title = \"Cluster View\"\n",
        "\n",
        "plot = datamapplot.create_interactive_plot(\n",
        "    data_map,\n",
        "    labels,\n",
        "    font_family=\"Cinzel\",\n",
        "    title=plvis_title,\n",
        "    sub_title=\"PLVis Project\",\n",
        "    hover_text=hover_data,\n",
        "    enable_search=True\n",
        ")\n",
        "plot.save(f\"{plvis_title}.html\")\n",
        "plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2OOlPc-qudF"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6kvzrD_C821t"
      },
      "outputs": [],
      "source": [
        "#@title Column Analysis\n",
        "#@markdown This next section allows the user to compare between two different\n",
        "#@markdown sets of data within the dataframe. To start, please run the cell and\n",
        "#@markdown select the column that you wish to analyze.\n",
        "\n",
        "cols_to_remove = ['Entry','Entry Name', 'Protein names', 'Sequence',\n",
        "                  'Length', 'UMAP 1', 'UMAP 2']\n",
        "\n",
        "cols = [col for col in complete_df.columns if col not in cols_to_remove]\n",
        "cols.insert(0, ' ')\n",
        "\n",
        "def selected_col(change):\n",
        "    global sel_col\n",
        "    sel_col = col_sel.value\n",
        "    if sel_col == ' ':\n",
        "        print(\"WARNING: please select a valid column\")\n",
        "    else:\n",
        "        print('Selected ', sel_col)\n",
        "\n",
        "col_sel = widgets.Dropdown(options=cols,\n",
        "                        description='Select Column:')\n",
        "col_sel.observe(selected_col, names='value')\n",
        "\n",
        "widgets.VBox([col_sel])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y_tppwSICIOG"
      },
      "outputs": [],
      "source": [
        "#@title Comparison Selection\n",
        "#@markdown Please run this cell and select the\n",
        "#@markdown comparison that you wish to study from the dropdown menu.\n",
        "\n",
        "options = complete_df[sel_col].unique()\n",
        "\n",
        "combinations = list(itertools.combinations(options, 2))\n",
        "combination_options = {f\"{a} vs {b}\": (a, b) for a, b in combinations}\n",
        "combination_options = {' ': None, **combination_options}\n",
        "\n",
        "def selected_comp(change):\n",
        "    global sel_comp\n",
        "    sel_comp = comp_sel.value\n",
        "    if sel_comp is None:\n",
        "        print(\"WARNING: please select a valid comparison\")\n",
        "    else:\n",
        "        print('Selected ', sel_comp)\n",
        "\n",
        "comp_sel = widgets.Dropdown(options=combination_options,\n",
        "                            description='Select Comparison:')\n",
        "comp_sel.observe(selected_comp, names='value')\n",
        "\n",
        "widgets.VBox([comp_sel])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lfoRNUFTFyj2"
      },
      "outputs": [],
      "source": [
        "#@title Comparison Visualization\n",
        "\n",
        "#@markdown Run this cell to visualize your comparison. Each entry studied is\n",
        "#@markdown colored in a different color to distinguish them.\n",
        "\n",
        "comp_df = complete_df\n",
        "comp_df = comp_df[comp_df[sel_col].isin(sel_comp)]\n",
        "data_map, hover_data, labels = get_data(comp_df)\n",
        "\n",
        "color_mapping = {sel_comp[0]: 'darkred',\n",
        "                 sel_comp[1]: 'darkblue'}\n",
        "\n",
        "marker_color_array = pd.Series(comp_df[sel_col]).map(color_mapping).values\n",
        "custom_css, custom_html, custom_js = get_customs(color_mapping)\n",
        "\n",
        "plvis_title = \"\" #@param {type:\"string\"}\n",
        "if plvis_title == \"\":\n",
        "    plvis_title = \"Comparison View\"\n",
        "\n",
        "plvis_comp = datamapplot.create_interactive_plot(\n",
        "    data_map,\n",
        "    font_family=\"Cinzel\",\n",
        "    title=plvis_title,\n",
        "    sub_title=\"PLVis project\",\n",
        "    hover_text=hover_data,\n",
        "    enable_search=True,\n",
        "    color_label_text=False,\n",
        "    marker_color_array=marker_color_array,\n",
        "    custom_css=custom_css,\n",
        "    custom_html=custom_html)\n",
        "\n",
        "plvis_comp.save(f\"{plvis_title}.html\")\n",
        "plvis_comp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSz6E-XGSLHl"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZYknyi_2Rysk"
      },
      "outputs": [],
      "source": [
        "#@title AlphaFold Structure Comparison\n",
        "#@markdown In this section you can visualize the available AlphaFold generated structures for\n",
        "#@markdown proteins within a cluster. Please run this cell and select a cluster\n",
        "#@markdown label from the dropdown menu to start.\n",
        "\n",
        "clus_labels = np.sort(complete_df['Cluster Label'].unique()).tolist()\n",
        "clus_labels.insert(0, ' ')\n",
        "\n",
        "def selected_clus(change):\n",
        "    global sel_clus\n",
        "    sel_clus = clus_sel.value\n",
        "    if sel_clus == ' ':\n",
        "        print(\"WARNING: please select a valid column\")\n",
        "    else:\n",
        "        print('Selected ', sel_clus)\n",
        "\n",
        "clus_sel = widgets.Dropdown(options=clus_labels,\n",
        "                            description='Cluster:')\n",
        "clus_sel.observe(selected_clus, names='value')\n",
        "\n",
        "widgets.VBox([clus_sel])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OQqBMZr0R37d"
      },
      "outputs": [],
      "source": [
        "#@title Retrieve the AlphaFold Structures\n",
        "#@markdown This cell downloads all the corresponding PDB files for the AlphaFold\n",
        "#@markdown structures of the proteins in the selected cluster.\n",
        "\n",
        "cluster_df = complete_df[complete_df['Cluster Label'] == \tsel_clus]\n",
        "\n",
        "pdb_dir = \"alphafold_structures\"\n",
        "if not os.path.exists(pdb_dir):\n",
        "    os.makedirs(pdb_dir)\n",
        "\n",
        "missing = []\n",
        "downloaded = []\n",
        "print(f'Retrieving {len(cluster_df)} files')\n",
        "for index, row in cluster_df.iterrows():\n",
        "    key = row['Entry']\n",
        "    pdb_file = os.path.join(pdb_dir, f'{key}.pdb')\n",
        "    if not os.path.exists(pdb_file):\n",
        "        download_alphafold_structure(key, out_dir = pdb_dir, aligned_score=False)\n",
        "        if not os.path.exists(pdb_file):\n",
        "            missing.append(key)\n",
        "        else:\n",
        "            downloaded.append(key)\n",
        "\n",
        "print(f'Successfully downloaded {len(downloaded)} files')\n",
        "print(f'Missing {len(missing)} files')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fjUZosk0R7Va"
      },
      "outputs": [],
      "source": [
        "#@title Structure Comparison\n",
        "\n",
        "#@markdown In this cell you can visualize a random selection of 9 proteins from\n",
        "#@markdown the selected cluster. Click on the viewer to rotate them.\n",
        "\n",
        "if not downloaded:\n",
        "    print(\"No available structures.\")\n",
        "else:\n",
        "\n",
        "    if len(downloaded) >= 9:\n",
        "        entries_list = random.sample(downloaded, 9)\n",
        "    else:\n",
        "        entries_list = downloaded\n",
        "\n",
        "    protein_list = []\n",
        "    for entry in entries_list:\n",
        "        try:\n",
        "            with open(f'alphafold_structures/{entry}.pdb', 'r') as file:\n",
        "                content = file.read()\n",
        "                protein_list.append(content)\n",
        "        except:\n",
        "            print(f'{entry} not available')\n",
        "\n",
        "    view = py3Dmol.view(viewergrid=(3,3), width=800, height=500, linked=True)\n",
        "    view.setViewStyle({'style':'outline','color':'k','width':0.1})\n",
        "    view.setBackgroundColor('black')\n",
        "\n",
        "    for i in range(len(protein_list)):\n",
        "        row = i//3\n",
        "        col = i%3\n",
        "        view.addModel(protein_list[i],'pdb',viewer=(row,col))\n",
        "        view.setStyle({\"cartoon\": {'color': 'spectrum'}},viewer=(row,col))\n",
        "        view.zoomTo(viewer=(row,col))\n",
        "\n",
        "        title = entries_list[i] if i < len(entries_list) else f\"Protein {i+1}\"\n",
        "        view.addLabel(title, {'fontColor':'white', 'fontSize':12, 'position': {'x':0, 'y':5, 'z':0}}, viewer=(row, col))\n",
        "\n",
        "    view.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
